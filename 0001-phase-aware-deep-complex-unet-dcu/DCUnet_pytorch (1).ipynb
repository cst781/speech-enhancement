{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCUnet.pytorch",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SappraI2J_a8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q soundfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjam5f753TCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone -q https://github.com/chanil1218/DCUnet.pytorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbGwn9QhJ4Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q \"HIDDEN/einschlafen-chunks-10s/einschlafen2-chunks-10000.tar\" -O - | tar xf -"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opNDdUO4HSJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"HIDDEN/einschlafen-chunks-10s/AIR_1_4.tar\" -O - | tar xf -"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H79jyI64G-ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKcshqC5IAVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "if 'DCUnet.pytorch' not in sys.path: sys.path.append('DCUnet.pytorch')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "from scipy.io import wavfile\n",
        "import librosa\n",
        "import tqdm\n",
        "\n",
        "import glob\n",
        "import utils\n",
        "from models.unet import Unet\n",
        "from models.layers.istft import ISTFT\n",
        "#from se_dataset import AudioDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model_dir', default='experiments/base_model', help=\"Directory containing params.json\")\n",
        "parser.add_argument('--restore_file', default=None, help=\"Optional, name of the file in --model_dir containing weights to reload before training\")  # 'best' or 'train'\n",
        "parser.add_argument('--batch_size', default=32, type=int, help='train batch size')\n",
        "parser.add_argument('--num_epochs', default=100, type=int, help='train epochs number')\n",
        "args = parser.parse_args()\n",
        "\"\"\"\n",
        "\n",
        "#n_fft, hop_length = 400, 160\n",
        "n_fft, hop_length = 1024, 256\n",
        "window = torch.hann_window(n_fft).cuda()\n",
        "stft = lambda x: torch.stft(x, n_fft, hop_length, window=window)\n",
        "istft = ISTFT(n_fft, hop_length, window='hanning').cuda()\n",
        "\n",
        "def wSDRLoss(mixed, clean, clean_est, eps=2e-7):\n",
        "    # Used on signal level(time-domain). Backprop-able istft should be used.\n",
        "    # Batched audio inputs shape (N x T) required.\n",
        "    bsum = lambda x: torch.sum(x, dim=1) # Batch preserving sum for convenience.\n",
        "    def mSDRLoss(orig, est):\n",
        "        # Modified SDR loss, <x, x`> / (||x|| * ||x`||) : L2 Norm.\n",
        "        # Original SDR Loss: <x, x`>**2 / <x`, x`> (== ||x`||**2)\n",
        "        #  > Maximize Correlation while producing minimum energy output.\n",
        "        correlation = bsum(orig * est)\n",
        "        energies = torch.norm(orig, p=2, dim=1) * torch.norm(est, p=2, dim=1)\n",
        "        return -(correlation / (energies + eps))\n",
        "\n",
        "    noise = mixed - clean\n",
        "    noise_est = mixed - clean_est\n",
        "\n",
        "    a = bsum(clean**2) / (bsum(clean**2) + bsum(noise**2) + eps)\n",
        "    wSDR = a * mSDRLoss(clean, clean_est) + (1 - a) * mSDRLoss(noise, noise_est)\n",
        "    return torch.mean(wSDR)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp6yNIPmEe-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import tarfile\n",
        "import soundfile as sf\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "try:\n",
        "    TARS, CLEAN = pickle.load(open('tars-clean.pk', 'rb'))\n",
        "except IOError:\n",
        "    TARS = glob.glob(\"/content/drive/My Drive/einschlafen-10s-AIRs/**/*.tar\", recursive=True)\n",
        "    TARS.sort()\n",
        "    CLEAN = glob.glob(\"einschlafen2/**/*.wav\", recursive=True)\n",
        "    CLEAN.sort()\n",
        "    pickle.dump((TARS, CLEAN), open('tars-clean.pk', 'wb'))\n",
        "\n",
        "SAMPLE_LEN = 3\n",
        "FIRST_FRAME = 16_000\n",
        "LAST_FRAME = SAMPLE_LEN * 16_000 + FIRST_FRAME\n",
        "\n",
        "TARS = TARS[:500]\n",
        "\n",
        "class MyAudioDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, tars, clean_files):\n",
        "        self.tars = tars\n",
        "        self.preloaded = []\n",
        "    \n",
        "    def __iter__(self):\n",
        "        tar_iter = iter(self.tars)\n",
        "        while True:\n",
        "            if not self.preloaded:\n",
        "                for _ in range(3):\n",
        "                    try:\n",
        "                        tar = next(tar_iter)\n",
        "                    except StopIteration:\n",
        "                        yield from self.preloaded\n",
        "                        return\n",
        "                    else:\n",
        "                        try:\n",
        "                            self.refill(tar, self.preloaded)\n",
        "                        except Exception as e:\n",
        "                            print(\"Error reading\", tar, e)\n",
        "                if not self.preloaded:\n",
        "                    raise RuntimeError(\"Could not read any tars\")\n",
        "            yield self.preloaded.pop()\n",
        "\n",
        "    def refill(self, tar, res):                \n",
        "        episode, chunk = tar.split(\"/\")[-1].split(\"-\", 1)\n",
        "        clean = f\"einschlafen2/{episode}/{episode}-{chunk[:-4]}\"\n",
        "        clean_data, clean_sr = sf.read(clean)\n",
        "        assert clean_sr == 16_000\n",
        "        clean_data = torch.from_numpy(clean_data[FIRST_FRAME:LAST_FRAME]).type(torch.FloatTensor)\n",
        "        with tarfile.open(tar) as tarf:\n",
        "            members = tarf.getmembers()\n",
        "            random.shuffle(members)\n",
        "            for member in members:\n",
        "                cur_f = tarf.extractfile(member)\n",
        "                noisy_data, noisy_sr = sf.read(cur_f)\n",
        "                assert noisy_sr == 16_000\n",
        "                noisy_data = torch.from_numpy(noisy_data[FIRST_FRAME:LAST_FRAME]).type(torch.FloatTensor)\n",
        "                res.append((noisy_data, clean_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ieDnohcIDwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 0:\n",
        "    params = utils.Params(\"DCUnet.pytorch/exp/unet16.json\")\n",
        "    net = Unet(params.model).cuda()\n",
        "else:\n",
        "    MODEL = {\n",
        "        \"leaky_slope\" : 0.1,\n",
        "        \"ratio_mask\" : \"BDT\",\n",
        "        \"encoders\" : [\n",
        "            [1, 32, [7, 5], [2, 2], [3, 2]],\n",
        "            [32, 64, [7, 5], [2, 2], [3, 2]],\n",
        "            [64, 64, [5, 3], [2, 2], [2, 1]],\n",
        "            [64, 64, [5, 3], [2, 2], [2, 1]],\n",
        "            [64, 64, [5, 3], [2, 1], [2, 1]]\n",
        "        ],\n",
        "        \"decoders\" : [\n",
        "            [64, 64, [5, 3], [2, 1], [2, 1]],\n",
        "            [128, 64, [5, 3], [2, 2], [2, 1]],\n",
        "            [128, 64, [5, 3], [2, 2], [2, 1]],\n",
        "            [128, 32, [7, 5], [2, 2], [3, 2]],\n",
        "            [64, 1, [7, 5], [2, 2], [3, 2]]\n",
        "        ],\n",
        "        \"__coder_keys\" : [\n",
        "            \"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"\n",
        "        ]\n",
        "    }\n",
        "    net = Unet(MODEL).cuda()\n",
        "\n",
        "print(\"Model has\", sum(p.numel() for p in net.parameters() if p.requires_grad)/1e6, \"M params\")\n",
        "\n",
        "# TODO - check exists\n",
        "START_EPOCH = 28\n",
        "N_EPOCHS = 50\n",
        "NET_NAME = 'net-2-'\n",
        "if START_EPOCH > 0:\n",
        "    checkpoint = torch.load(f'/content/drive/My Drive/{NET_NAME}{START_EPOCH-1}.pth.tar')\n",
        "    net.load_state_dict(checkpoint)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = MyAudioDataset(TARS, CLEAN)\n",
        "train_data_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    ) #collate_fn=train_dataset.collate,#, num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKYWP1bGrC4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    torch.set_printoptions(precision=10, profile=\"full\")\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
        "    # Learning rate scheduler\n",
        "    scheduler = ExponentialLR(optimizer, 0.95)\n",
        "\n",
        "    #mse_loss = torch.nn.MSELoss()\n",
        "\n",
        "    for epoch in range(START_EPOCH, START_EPOCH+N_EPOCHS):\n",
        "        train_bar = tqdm.notebook.tqdm(train_data_loader, total=int(len(TARS) * 214 / BATCH_SIZE))\n",
        "        ct = 0\n",
        "        for train_mixed_cpu, train_clean_cpu in train_bar:\n",
        "            ct += 1\n",
        "            train_mixed = train_mixed_cpu.cuda()\n",
        "\n",
        "            mixed_spec = stft(train_mixed).unsqueeze(dim=1)\n",
        "            mixed_real, mixed_imag = mixed_spec[..., 0], mixed_spec[..., 1]\n",
        "\n",
        "            out_real, out_imag = net(mixed_real, mixed_imag)\n",
        "            train_clean = train_clean_cpu.cuda()\n",
        "\n",
        "            #clean_spec = stft(train_clean).unsqueeze(dim=1)\n",
        "            #clean_real, clean_imag = clean_spec[..., 0], clean_spec[..., 1]\n",
        "            #out_spec = torch.cat([torch.unsqueeze(out_real, 4), torch.unsqueeze(out_imag, 4)], dim=4)\n",
        "            #loss = mse_loss(clean_spec, out_spec)\n",
        "\n",
        "            out_real, out_imag = torch.squeeze(out_real, 1), torch.squeeze(out_imag, 1)\n",
        "            out_audio = istft(out_real, out_imag, train_mixed.size(1))\n",
        "            out_audio = torch.squeeze(out_audio, dim=1)\n",
        "            #for i, l in enumerate(seq_len):\n",
        "            #    out_audio[i, l:] = 0\n",
        "            #librosa.output.write_wav('mixed.wav', train_mixed[0].cpu().data.numpy()[:seq_len[0].cpu().data.numpy()], 16000)\n",
        "            #librosa.output.write_wav('clean.wav', train_clean[0].cpu().data.numpy()[:seq_len[0].cpu().data.numpy()], 16000)\n",
        "            #librosa.output.write_wav('out.wav', out_audio[0].cpu().data.numpy()[:seq_len[0].cpu().data.numpy()], 16000)\n",
        "            loss = wSDRLoss(train_mixed, train_clean, out_audio)\n",
        "\n",
        "            if ct % 30 == 0:\n",
        "                print(epoch, loss)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "        torch.save(net.state_dict(), f'/content/drive/My Drive/{NET_NAME}{epoch}.pth.tar')\n",
        "    #torch.save(net.state_dict(), './final.pth.tar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK_0HxHGzyx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_samples(mixed):\n",
        "    mixed_spec = stft(mixed.cuda()).unsqueeze(dim=1)\n",
        "    mixed_real, mixed_imag = mixed_spec[..., 0], mixed_spec[..., 1]\n",
        "    out_real, out_imag = net(mixed_real, mixed_imag)\n",
        "    out_real, out_imag = torch.squeeze(out_real, 1), torch.squeeze(out_imag, 1)\n",
        "    out_audio = istft(out_real, out_imag, mixed.size(1))\n",
        "    out_audio = torch.squeeze(out_audio, dim=1)\n",
        "    return out_audio\n",
        "\n",
        "def eval_():\n",
        "    train_data_loader_it = iter(train_data_loader)\n",
        "    for _ in range(random.randint(0,5)*BATCH_SIZE):\n",
        "        next(train_data_loader_it)\n",
        "    train_mixed_cpu, train_clean_cpu = next(train_data_loader_it)\n",
        "\n",
        "    randidx = random.randint(0, train_mixed_cpu.shape[0]-1)\n",
        "    mixed = train_mixed_cpu[randidx:randidx+1]\n",
        "    out_audio = eval_samples(mixed)\n",
        "    train_clean = train_clean_cpu[randidx:randidx+1].cuda()\n",
        "    librosa.output.write_wav('mixed.wav', mixed[0].cpu().data.numpy(), 16000)\n",
        "    librosa.output.write_wav('clean.wav', train_clean[0].cpu().data.numpy(), 16000)\n",
        "    librosa.output.write_wav('out.wav', out_audio[0].cpu().data.numpy(), 16000)\n",
        "\n",
        "#eval_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR_ZsOJS7eNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "episodes = set(c.split('/')[1] for c in CLEAN)\n",
        "\n",
        "conseq = []\n",
        "for episode in episodes:\n",
        "    chunks = [c for c in CLEAN if episode in c]\n",
        "    chunks = sorted(chunks, key=lambda c: (int(c.split('-')[-3]), int(c.split('-')[-2])))\n",
        "    conseq.append([chunks[0]])\n",
        "    for chunk in chunks[1:]:\n",
        "        if not conseq:\n",
        "            conseq.append([chunk])\n",
        "        else:\n",
        "            prev_rir = conseq[-1][-1].split('-')[-3]\n",
        "            prev_end = conseq[-1][-1].split('-')[-1][:-4]\n",
        "            cur_start = chunk.split('-')[-2]\n",
        "            cur_rir = chunk.split('-')[-3]\n",
        "            if prev_rir != cur_rir or prev_end != cur_start:\n",
        "                conseq.append([chunk])\n",
        "            else:\n",
        "                conseq[-1].append(chunk)\n",
        "\n",
        "conseq = [c for c in conseq if len(c) > 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C60QU9XGS3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.signal\n",
        "\n",
        "def test_sample(clean):\n",
        "    mixed = scipy.signal.convolve(\n",
        "        clean,\n",
        "        librosa.core.load(random.choice(glob.glob(\"AIR_1_4/*wav\")), sr=None)[0][:16000]\n",
        "    )[16000:-16000]\n",
        "\n",
        "    nsplit = len(mixed) // (SAMPLE_LEN*16000)\n",
        "    audiolen = nsplit * (SAMPLE_LEN*16000)\n",
        "    return clean[16000:-16000], mixed, eval_sample(\n",
        "        torch.from_numpy(mixed[:audiolen].reshape((nsplit, -1))\n",
        "                        ).type(torch.FloatTensor)\n",
        "    ).reshape(audiolen).cpu().data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDhNRfBgOwRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conseq_sample_clean, conseq_sample_mixed, conseq_sample_out = test_sample(\n",
        "    np.concatenate([librosa.core.load(wav,sr=None)[0] for wav in conseq[1]])\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0k28WB3Qop8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "librosa.output.write_wav(\"conseq-clean.wav\", conseq_sample_clean*0.1,sr=16000)\n",
        "librosa.output.write_wav(\"conseq-mixed.wav\", conseq_sample_mixed*0.1,sr=16000)\n",
        "librosa.output.write_wav(\"conseq-out.wav\", conseq_sample_out*0.1,sr=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVwrV_0UNqjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Id.Audio(conseq_sample_mixed,rate=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDMoZyP2NsQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Id.Audio(conseq_sample_out,rate=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SxBSjZWQ74w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagesschau_clean, tagesschau_mixed, tagesschau_out = test_sample(\n",
        "    librosa.core.load(\"tagesschau---orig.wav\",sr=16000, duration=20)[0]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiq7x9cbRFq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Id.Audio(tagesschau_mixed,rate=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEQgBkr0R3if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Id.Audio(tagesschau_out,rate=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNTwAQU0SRcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "librosa.output.write_wav(\"tagesschau-clean.wav\", tagesschau_clean*0.1,sr=16000)\n",
        "librosa.output.write_wav(\"tagesschau-mixed.wav\", tagesschau_mixed*0.1,sr=16000)\n",
        "librosa.output.write_wav(\"tagesschau-out.wav\", tagesschau_out*0.1,sr=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J37La99n05p2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display as Id\n",
        "\n",
        "Id.Audio(\"clean.wav\", rate=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js9vA4hF1GRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Id.Audio(\"mixed.wav\", rate=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C6zKnlT1HOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Id.Audio(\"out.wav\", rate=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyLC2ZEPPgLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc; gc.collect()\n",
        "\n",
        "def pretty_size(size):\n",
        "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
        "\tassert(isinstance(size, torch.Size))\n",
        "\treturn \" × \".join(map(str, size))\n",
        "\n",
        "def dump_tensors(gpu_only=True):\n",
        "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
        "\timport gc\n",
        "\ttotal_size = 0\n",
        "\tfor obj in gc.get_objects():\n",
        "\t\ttry:\n",
        "\t\t\tif torch.is_tensor(obj):\n",
        "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
        "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
        "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
        "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
        "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
        "\t\t\t\t\ttotal_size += obj.numel()\n",
        "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
        "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
        "\t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
        "\t\t\t\t\ttotal_size += obj.data.numel()\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tpass        \n",
        "\tprint(\"Total size:\", total_size)\n",
        " \n",
        "dump_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
